---
title: "Predicting Airbnb Prices in New York City"
author: "Jack Cunningham & Ali Fazl"
date: "`r Sys.Date()`"
output: pdf_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = FALSE)
knitr::opts_chunk$set(warning = FALSE, message = FALSE) 
options(`mosaic:parallelMessage` = FALSE)
library(cowplot)
library(tidyverse)
library(gamlr)
library(gridExtra)
library(tidytext)
library(dbscan)
library(parallel)
library(dplyr)
library(knitr)
library(glmnet)
library(tm)
library(ggplot2)
library(igraph)
library(arules)
library(arulesViz)
library(mosaic)
library(rpart)
library(rpart.plot)
library(rsample) 
library(randomForest)
library(lubridate)
library(caret)
library(Matrix)
library(modelr)
library(gbm)
library(pdp)
library(ggmap)
library(cluster)
library(tidycensus)
library(MazamaLocationUtils)
library(ggcorrplot)
library(tigris)
library(fuzzyjoin)
library(sf)
library(data.table)
NY_Spring <- read.csv("/Users/jack/Documents/GitHub/Data-Mining-Statistical-Learning/Final Project/listings 2.csv")
NY_Winter <- read.csv("/Users/jack/Documents/GitHub/Data-Mining-Statistical-Learning/Final Project/dec22.csv")
NY_Summer <- read.csv("/Users/jack/Documents/GitHub/Data-Mining-Statistical-Learning/Final Project/june22.csv")
NY_Fall <- read.csv("/Users/jack/Documents/GitHub/Data-Mining-Statistical-Learning/Final Project/sept22.csv")
```

```{r 1}
####Data Cleaning
NY_Spring <- NY_Spring %>%
  mutate(spring = 1) %>%
  mutate(summer = 0) %>%
  mutate(fall = 0) %>%
  mutate(winter = 0)

#change the format
NY_Spring$host_since <- as.Date(NY_Spring$host_since, format = "%Y-%m-%d")
Data_collection_d <- as.Date("2023-03-15")
#since how many years ago he/she has been a host:
NY_Spring$host_since <- as.numeric(difftime(Data_collection_d, NY_Spring$host_since,
                                            units = "days")) / 365.25

NY_Summer <- NY_Summer %>%
  mutate(spring = 0) %>%
  mutate(summer = 1) %>%
  mutate(fall = 0) %>%
  mutate(winter = 0)

#change the format
NY_Summer$host_since <- as.Date(NY_Summer$host_since, format = "%m/%d/%y")
Data_collection_d <- as.Date("2022-06-15")
#since how many years ago he/she has been a host:
NY_Summer$host_since <- as.numeric(difftime(Data_collection_d, NY_Summer$host_since,
                                            units = "days")) / 365.25

NY_Fall <- NY_Fall %>%
  mutate(spring = 0) %>%
  mutate(summer = 0) %>%
  mutate(fall = 1) %>%
  mutate(winter = 0)

#change the format
NY_Fall$host_since <- as.Date(NY_Fall$host_since, format = "%Y-%m-%d")
Data_collection_d <- as.Date("2022-09-15")
#since how many years ago he/she has been a host:
NY_Fall$host_since <- as.numeric(difftime(Data_collection_d, NY_Fall$host_since,
                                          units = "days")) / 365.25

NY_Winter <- NY_Winter %>%
  mutate(spring = 0) %>%
  mutate(summer = 0) %>%
  mutate(fall = 0) %>%
  mutate(winter = 1)

#change the format
NY_Winter$host_since <- as.Date(NY_Winter$host_since, format = "%Y-%m-%d")
Data_collection_d <- as.Date("2022-12-15")
#since how many years ago he/she has been a host:
NY_Winter$host_since <- as.numeric(difftime(Data_collection_d, NY_Winter$host_since,
                                            units = "days")) / 365.25

#merging seasons
NY_BNB <- rbind(NY_Spring, NY_Summer, NY_Fall, NY_Winter)

#remove unused columns
NY_BNB <- NY_BNB[, -c(2,3,4,5,8,9,10,11,12,14,15,16,17,18,19,20,21,22,23,
                      25,26,28,33,36,43,44,45,46,47,48,49,50,51,56,58,59,
                      60,61,69,71,72,73,74)]

#change $price to integer
NY_BNB$price <- as.integer(gsub("[,$]", "", NY_BNB$price))
NY_BNB = NY_BNB %>%
  mutate(log_price = log(price))

#NY_BNB2 that contains only the rows of the original data frame NY_BNB
#that do not have any missing values.
NY_BNB2 <- NY_BNB[complete.cases(NY_BNB), ]

#change "f,t" format to 0 and 1
NY_BNB2$host_identity_verified <- ifelse(NY_BNB2$host_identity_verified == "t", 1, 0)
NY_BNB2$instant_bookable <- ifelse(NY_BNB2$instant_bookable == "t", 1, 0)

#drop if host_since <=1
NY_BNB2 = NY_BNB2 %>%
  filter(host_since >= 1)

# Creating dummies:
NY_BNB2 = NY_BNB2 %>%
  mutate(shared_room = ifelse(room_type == "Shared room", 1, 0))
NY_BNB2 = NY_BNB2 %>%
  mutate(private_room = ifelse(room_type == "Private room", 1, 0))
NY_BNB2 = NY_BNB2 %>%
  mutate (entire_home = ifelse(room_type == "Entire home/apt", 1, 0))
NY_BNB2 = NY_BNB2 %>%
  mutate (hotel_room = ifelse(room_type == "Hotel room", 1, 0))

# amenities:
words_to_search <- c("Pets allowed", "Kitchen", "Elevator", "Air conditioning", 
                     "Heating", "Long term stays allowed")
NY_BNB2 <- NY_BNB2 %>%
  mutate(Pets_allowed = as.integer(grepl(words_to_search[1], amenities)),
         Kitchen = as.integer(grepl(words_to_search[2], amenities)),
         Elevator = as.integer(grepl(words_to_search[3], amenities)),
         Air_conditioning = as.integer(grepl(words_to_search[4], amenities)),
         Heating = as.integer(grepl(words_to_search[5], amenities)),
         Long_term_allowed = as.integer(grepl(words_to_search[6], amenities)))

# Normalize latitude and longitude
NY_BNB2$latitude_normalized <- (NY_BNB2$latitude - min(NY_BNB2$latitude)) / (max(NY_BNB2$latitude) - min(NY_BNB2$latitude))

NY_BNB2$longitude_normalized <- (NY_BNB2$longitude - min(NY_BNB2$longitude)) / (max(NY_BNB2$longitude) - min(NY_BNB2$longitude))

# Function to calculate Haversine distance
haversine_distance <- function(lat1, lon1, lat2, lon2) {
  R <- 6371 # Earth's radius in kilometers
  delta_lat <- (lat2 - lat1) * pi / 180
  delta_lon <- (lon2 - lon1) * pi / 180
  a <- sin(delta_lat / 2) * sin(delta_lat / 2) +
    cos(lat1 * pi / 180) * cos(lat2 * pi / 180) *
    sin(delta_lon / 2) * sin(delta_lon / 2)
  c <- 2 * atan2(sqrt(a), sqrt(1 - a))
  d <- R * c
  return(d)
}

# Reference point (center of the city)
ref_latitude <- 40.71745
ref_longitude <- -74.00385

# Calculate the Haversine distance for each listing
NY_BNB2$distance_from_center <- mapply(haversine_distance, NY_BNB2$latitude, 
                                       NY_BNB2$longitude, ref_latitude, ref_longitude)

# Random sample:
set.seed(1)
NY_reduced <- NY_BNB2 %>%
  sample_frac(0.25)

## Location clusters
coords <- cbind(NY_reduced$latitude, NY_reduced$longitude)

set.seed(1)
# Run the DBSCAN clustering algorithm
# Set the eps parameter (maximum distance between points in the same cluster)
# and the MinPts parameter (minimum number of points to form a dense region)
dbscan_result <- dbscan(coords, eps = 0.0025, minPts = 20)

# Add the cluster assignments to the dataset
NY_reduced$spatial_cluster <- as.factor(dbscan_result$cluster)

# Filter the data to the price range between 0 and 1500 USD
NY_reduced <- NY_reduced[NY_reduced$price >= 0 & NY_reduced$price <= 1500, ]

# How many data points did we remove for the filtered price dataset?
total_observations <- nrow(NY_reduced)
filtered_observations <- nrow(NY_reduced)
percentage_filtered <- (total_observations - filtered_observations) / total_observations * 100

# We only lost ~0.4% of observations.

view(NY_reduced)

write.csv(NY_reduced, file = "/Users/jack/Documents/GitHub/Data-Mining-Statistical-Learning/Final Project/NY_reduced.csv",
          row.names = FALSE)
####the end of Data Cleaning
```

## Abstract:

In this project, we predict the price of New York City Airbnb listings using various machine learning models. The random forest model performs the best, with an RMSE of 0.323, despite the inherent challenges in predicting a variable with many upper outliers. Our model identifies four main categories of features that best predict price: location, property type, minimum stay requirements, and host-specific features. Seasonal factors and certain amenities had minimal impact on price.

Although the random forest model outperforms other methods, it still has a relatively high RMSE, likely due to potential issues with both the model itself and the data. Issues in feature selection and unobserved variations in hosts' price-setting might contribute to the model's error. Additionally, limitations in capturing location information and seasonality may hinder the model's predictive power. The model performs reasonably well in most of Manhattan above Midtown and in most of Brooklyn outside of Downtown Brooklyn, while it exhibited spottier performance in sparse areas on the outskirts of the city and in the most expensive areas of Lower Manhattan and Downtown Brooklyn.

Our findings provide valuable insights for both Airbnb hosts and travelers. Hosts should focus on property location, type, minimum stay requirements, and maintaining a good reputation to optimize their pricing strategy. Travelers can use this information to compare similar listings, prioritize important features, and find the best value for their money. However, due to the limited number of price data points and the relatively high error rate of our model, both hosts and travelers should interpret these findings with caution.

 

## Introduction:

Our question is: What factors best predict Airbnb prices in New York City, and how can hosts and travelers use that information?

The rise of the sharing economy has transformed the way people travel and seek accommodations. Platforms such as Airbnb have gained popularity by allowing property owners to rent out their homes or rooms to travelers, offering an alternative to traditional hotels. New York City sees over 50 million visitors per year; the city has experienced significant growth in its Airbnb market, with tens of thousands of active listings at any given time. Accurate prediction of Airbnb prices is essential for hosts to optimize their revenue and for travelers to make informed decisions when selecting accommodations. This project aims to examine the factors that best predict Airbnb prices in New York City.

The audience for this project is hosts and travelers who want to understand the factors that predict New York's Airbnb prices. Travelers might be interested in saving money; understanding the factors that are most important for price, and the geographical locations of the most and least expensive Airbnbs, could help in that goal. And hosts, seeking to maximize revenue, will be curious about the factors that predict price for the same reasons travelers are. (Since we restrict the model to hosts who have been on the platform for at least a year, we aim this project's findings at established NYC hosts rather than new entrants.) The model in this project gives insight into pricing for a wide range of properties across the city; hosts could use the predicted prices of similar properties to set their own pricing strategies.

Spatial geography turns out to be a key predictor of New York's Airbnb prices; as the saying goes, location, location, location. To better understand how well our predictive model performs in each neighborhood, we map the neighborhood mean predicted prices of New York's Airbnbs against their actual mean prices, and we map the percent error of our model by neighborhood. This helps the reader understand where in the city our model does a good job predicting prices, and thus how well calibrated our model is to their neighborhood of interest.

In this project, we employ various machine learning techniques, including LASSO regression, random forest, and gradient boosting, to best predict Airbnb prices based on a comprehensive set of variables. We leverage a clustering algorithm, DBSCAN, to capture spatial patterns in the data and map predicted vs. actual prices. By doing so, we aim to enhance our understanding of the factors driving Airbnb prices in New York City and provide valuable insights for hosts and travelers alike.

 

## Methods:

### Data

For this project, we use four datasets combined into one. Each dataset contains the entire set of scraped NYC Airbnb listings at the following dates: June 15, 2022; September 15, 2022; December 15, 2022; and March 15, 2023. The combined data contain 70+ variables and more than 160,000 total listings (roughly 40,000 per quarter). These data come from InsideAirbnb: <http://insideairbnb.com/get-the-data/>.

We made some important modifications to the dataset in order to meet our needs:

-   Creating dummy variables for each season (June is summer, September is fall, December is winter, and March is spring), depending on which initial dataset the observation came from.

-   Modifying the host_since variable to provide a number of years since the start of the host's presence on Airbnb.

-   Removing roughly half the columns which we did not use in our analysis.

-   Dropping all observations with host_since \< 1 year. This ensures that all the listings come from hosts who have been on the platform for at least one year, helping to ease concerns about seasonal effects.

-   Dropping all observations with N/A values in any of the remaining fields. Among other effects, this ensures that our dataset includes only listings with at least one review, host-provided descriptions, and complete information about amenities, bedrooms, etc. We recognize that this might introduce some measurement error in our model (in fact, the correlation between listings that have N/A's in the remaining fields and price is positive but small, 0.0387; see code block below). However, filtering out "low quality", ie. incomplete, listings and those which had never been reviewed better addresses our intended audience.

```{r 1.1}
# Check if a row has at least one NA value
NY_BNB$has_NA <- apply(NY_BNB, 1, function(x) any(is.na(x)))

# Split the dataset into two parts: with NA values and without NA values
with_na <- NY_BNB[which(NY_BNB$has_NA),]
without_na <- NY_BNB[which(!NY_BNB$has_NA),]

# Convert the has_NA column to numeric values (1 for TRUE, 0 for FALSE)
NY_BNB$has_NA_numeric <- as.numeric(NY_BNB$has_NA)

# Calculate the correlation between the presence of NA values and the price
correlation <- cor(NY_BNB$has_NA_numeric, NY_BNB$price, use = "pairwise.complete.obs")
```

-   Manipulating variables to be easier to work with, e.g. adding dummy variables for room_type and changing f/t format to 0/1.

-   Normalizing latitude and longitudes to a range between 0 and 1.

-   Computing Haversine distance (distance_from_center), a measure of total distance of the listing's coordinates from Lower Manhattan, which has NYC's highest average Airbnb prices.

-   Using the DBSCAN clustering algorithm to spatially cluster the listings, to create another spatial variable beyond latitude and longitude to use as a predictor in our models.

-   Extracting six important terms from the "amenities" list to use as predictors in our models.

-   Filtering extreme price outliers (those over \$1500, roughly 0.4% of our dataset).

We then took a random sample of 25% of the cleaned data to use for our analysis. This sample still has over 25,000 observations of 42 variables. Reducing the dataset via random selection makes it easier to work with computationally while not sacrificing much accuracy, especially since we are working with full data on all of NYC's Airbnbs.

The most important reason we combined the four datasets into one is that it gives us a snapshot of seasonality. We only have price data for the dates that each dataset was scraped (6/15/22, 9/15/22, 12/15/22, and 3/15/23). One limitation of our dataset is that we don't have daily price data for a year; this would have been desired in order to uncover seasonal trends and variation with more fidelity. However, quarterly price data provides a rough proxy of seasonal price trends. As our results will show, season is not a particularly important predictor of NYC Airbnb prices.

We used repeated trial and error to develop spatial location factors that could be of use in our model. We tried normalizing latitude and longitude to a (0, 1) range, applying the DBSCAN clustering algorithm, and computing distance from the most expensive neighborhood of Lower Manhattan in order to construct a variety of location-based predictors of price. Each of these methods of including location features added predictive power to our model.

One other important note about our dataset is that we treat each listing as unique, despite the fact that many of the listings are run by the same hosts in each period. The reason for this approach is that many of the variables we use as predictors can change from one quarter to the next; e.g., review scores, availability data, and number of reviews, among many more. Hence, it makes more sense to treat each observation as unique, rather than simply extracting the seasonal prices for each listing and attaching them to one of the seasonal datasets.

The plots that follow give a sense of how price relates to some of the important variables in this dataset, including how many guests the listing can accommodate, minimum length of stay, listings of each room type, and overall review scores.

 

```{r 2, fig.height=3}
## Understanding the Data
# Calculate mean price for each integer value of accommodates
mean_price_by_accommodates <- NY_reduced %>%
  group_by(accommodates) %>%
  summarize(mean_price = mean(price, na.rm = TRUE))

# Plot the mean price for each integer value of accommodates
plot_1 <- ggplot(mean_price_by_accommodates, aes(x = accommodates, y = mean_price)) +
  geom_point() +
  geom_line(group = 1) +
  labs(title = "Mean Price by Accommodates",
       x = "Accommodates",
       y = "Mean Price") +
  theme_minimal()

# Calculate mean price for each integer value of minimum stay
mean_price_by_minimum_nights <- NY_reduced %>%
  group_by(minimum_nights) %>%
  summarize(mean_price = mean(price, na.rm = TRUE))

# Plot the mean price for each integer value of accommodates
plot_2 <- ggplot(mean_price_by_minimum_nights, aes(x = minimum_nights, y = mean_price)) +
  geom_point() +
  geom_line(group = 1) +
  labs(title = "Mean Price by Minimum Nights",
       x = "Minimum Nights",
       y = "Mean Price") +
  theme_minimal() + 
  scale_x_continuous(limits = c(0, 35)) 

# Price - Room Type
plot_3 <- ggplot(NY_reduced, aes(x = room_type, y = price)) +
  geom_boxplot(fill = "green") +
  labs(x = "Room Type", y = "Price") 

# Price - Review Scores
plot_4 <- ggplot(NY_reduced, aes(x = review_scores_rating, y = price))+
  geom_point(size = 0.1) +
  labs(x = "Overall Review Score", y = "Price") 

plot_1
```

 

```{r 2.1, fig.height=3}
plot_2
```

 

```{r 2.2, fig.height=3}
plot_3
```

 

```{r 2.3, fig.height=3}
plot_4
```

 

These plots demonstrate that some of the variables that we think have a big impact on price, like accommodates and room type, have a clear (if noisy) relationship, while others are much less clear. For example, it's hard to tell if there's a downward relationship between minimum price and nights or if that's just noise in the dataset. And in the review score plot, there is so much mass in the square between 4 and 5 review score and \$0 and \$500 price that it's hard to see any relationship, other than with outliers.

Given this initial glance at the dataset, it's clear that we will have our work cut out for us in trying to predict price. In the next section, we will describe the approach we took in order to build the best predictive model of price possible, despite the noise.

 

### Approach

We used a selection of methods in order to create the best price prediction model possible with this dataset. We trained each model on 80% of the cleaned dataset, then tested its root mean squared error using the remaining 20% of the dataset. The outcome of interest here is log price instead of price, in order to help normalize the distribution; as we will demonstrate below, the price variable is heavily left-skewed. This transformation also helps in the case that the relationship between our predictors and the price is non-linear.

We first tried a simple linear model, including just a few factors we thought would likely prove important, including location, property type, and review score. We then used the LASSO method with all the variables in the cleaned dataset in order to determine the most important ones; then, we ran a linear model using only the variables selected in the LASSO process.

Then, we turned to more sophisticated machine learning techniques: random tree, random forest, and gradient boosting. We tweaked each of these models via trial-and-error, adding and removing predictor variables as appropriate for the model. The random forest model turned out to have the best performance; we plotted the importance of each variable in this model in order to determine the most important factors affecting price.

Finally, in order to map our selected model's performance in each neighborhood, we first added the predicted price values from the random forest model to the dataset for each listing. Then, we calculated the mean predicted price in each of the 253 distinct New York City neighborhoods in our dataset, along with the actual mean prices for each neighborhood, and calculated the error rate. Finally, we plotted all three of these measures for each listing by latitude and longitude, along with NYC's geographic boundaries.

 

## Results:

### Understanding Price

Price in our dataset is left-skewed; while some listings exceed \$1000 per night, 75% of listings are \$200 or less.

 

```{r 3}
## Understanding Price
quartiles <- summary(NY_reduced$price)
quartiles

# Create a histogram of price values
ggplot(NY_reduced, aes(x = price)) +
  geom_histogram(binwidth = 10, color = "black", fill = "blue") +
  labs(title = "Histogram of Price Values (0 - 1500 USD)", x = "Price", y = "Frequency")
```

 

Manhattan has the most expensive listings, with a median nightly price of \$160. Brooklyn follows at \$119 per night; listings in the other boroughs have median nightly prices between \$80 and \$100. Each borough has quite a few upper outliers in price, as demonstrated by the boxplot below.

 

```{r 3.1}
# Price by neighborhood
median_prices_neighborhood <- NY_reduced %>%
  group_by(neighbourhood_group_cleansed) %>%
  summarize(median_price = median(price))

kable(median_prices_neighborhood)

# Boxplot by neighborhood:
ggplot(NY_reduced, aes(x = neighbourhood_group_cleansed, y = price)) +
  geom_boxplot(color = "black", fill = "blue") +
  labs(title = "Boxplot of Price by Neighborhood Group", 
       x = "Neighborhood Group", y = "Price")
```

 

Below, we've included the median listing price across the city by room type and season. Hotel rooms are by far the most expensive, although they are the least common. Entire homes are more than twice as expensive as private rooms, and nearly three times as expensive as shared rooms.

```{r 3.2}
# Price by room type
median_prices_room_type <- NY_reduced %>%
  group_by(room_type) %>%
  summarize(median_price = median(price))

kable(median_prices_room_type)
```

 

Season appears not to affect citywide median price much. The median price in each season ranges from \$120 in spring to \$130 in winter. Again, since we only have price data for one date per season, we lack the fine-grained price data that would be useful to identify bigger seasonal shifts, or price trends for each neighborhood (especially during e.g. big events or holidays). But for many listings in our dataset, the listed price was identical for each of the four dates of scraped data. It's possible that many Airbnb hosts don't change their prices much or at all from the default, although without better data this hypothesis is just speculation.

At the borough level, there is more seasonal variation in median price in some boroughs, and less in others. The range of Staten Island's median price by season is 25, while the range of Queens's median price by season is just 4.5. Of listings for which we have four observations, 51% had the same price at each observation date, suggesting that most Airbnb hosts do not change their listing price at all.

 

```{r 3.3}
# Price by season
# Compute the mean price for each season
median_price_by_season <- NY_reduced %>%
  gather(season, flag, spring:winter) %>%
  filter(flag == 1) %>%
  group_by(season) %>%
  summarise(median_price = median(price, na.rm = TRUE))

kable(median_price_by_season)

# Calculate median price by neighborhood per season
median_price_by_neighborhood_season <- NY_reduced %>%
  gather(season, flag, spring:winter) %>%
  filter(flag == 1) %>%
  group_by(neighbourhood_group_cleansed, season) %>%
  summarise(median_price = median(price, na.rm = TRUE))

# Print the result
kable(median_price_by_neighborhood_season)

# How many listings with the same id had the same price at all four dates?
four_id <- NY_reduced %>%
  group_by(id) %>%
  mutate(count = n()) %>%
  filter(count == 4) %>%
  ungroup()

percent_same_price <- four_id %>%
  group_by(id) %>%
  summarise(unique_prices = n_distinct(price)) %>%
  mutate(same_price = unique_prices == 1) %>%
  summarise(same_price_percentage = mean(same_price) * 100)
```

 

### Building a Prediction Model

The table below gives the RMSE of each model we tested. The best-performing model is the random forest model, which has a RMSE of 0.323; on average, this model is roughly (e\^(0.323) - 1) \* 100 = 38% off of the true price of a given listing.

 

```{r 4}
## Predicting Price ($0-1500)
set.seed(2)
NY_reduced_split = initial_split(NY_reduced, prop=0.8)
NY_reduced_train = training(NY_reduced_split)
NY_reduced_test  = testing(NY_reduced_split)

lm_null <- lm(log_price ~ 1, data = NY_reduced_train)

lm2 <- lm(log_price ~ latitude_normalized*longitude_normalized + review_scores_rating + 
            bedrooms + neighbourhood_group_cleansed + entire_home +
            shared_room + private_room, 
          data = NY_reduced_train)

lm3 <- lm(log_price ~ Pets_allowed + Kitchen + Elevator + Air_conditioning +
            Heating + Long_term_allowed, data = NY_reduced_train)

#LASSO
# create your own numeric feature matrix.
x1 = sparse.model.matrix(log_price ~ .-1 - price - name - description - 
                           amenities - neighbourhood_cleansed, 
                         data=NY_reduced)
y1 = NY_reduced$price

# fit a single lasso
set.seed(2) # Set seed for reproducibility
lasso1 = gamlr(x1, y1, family="gaussian", penalty.factor=1)

# the coefficients at the AIC-optimizing value
scbeta1 = coef(lasso1)
scbeta1_nonzero <- which(scbeta1 != 0, arr.ind = TRUE)

# Linear Model, (some) LASSO features
lm_lasso1 <- lm(log_price ~ host_since + neighbourhood_group_cleansed + Kitchen +
                  accommodates + spatial_cluster + minimum_nights + Elevator + 
                  Air_conditioning + Heating + review_scores_rating + 
                  host_total_listings_count + bathrooms_text + host_identity_verified +
                  latitude_normalized * longitude_normalized + number_of_reviews +
                  entire_home + shared_room + distance_from_center + 
                  reviews_per_month + review_scores_location + review_scores_value +
                  spring + fall, data = NY_reduced_train)

# random tree
BNB.tree1 = rpart(log_price ~ spatial_cluster + host_since + distance_from_center +
                    neighbourhood_group_cleansed + host_total_listings_count +
                    accommodates + bedrooms + minimum_nights + availability_30 +
                    availability_90 + number_of_reviews + review_scores_cleanliness +
                    reviews_per_month + review_scores_location + review_scores_value +
                    review_scores_rating + instant_bookable + entire_home + 
                    shared_room + private_room + spring + summer + fall + winter,
                       data=NY_reduced_train, control = rpart.control(cp = 0.00001))

# random forest
BNB.forest1 = randomForest(log_price ~ spatial_cluster + distance_from_center + 
                             latitude_normalized * longitude_normalized + 
                             host_since + neighbourhood_group_cleansed +
                             Air_conditioning + Heating + Kitchen + Elevator +
                             host_total_listings_count + accommodates + bedrooms +
                             minimum_nights + availability_30 + availability_90 +
                             reviews_per_month + review_scores_location +
                             number_of_reviews + review_scores_cleanliness +
                             review_scores_value + review_scores_rating +
                             instant_bookable + entire_home + shared_room + 
                             private_room + spring + summer + fall + winter,
                           data=NY_reduced_train, importance=TRUE)

# boosted model
BNB.boost1 = gbm(log_price ~ spatial_cluster + latitude_normalized*longitude_normalized +
                   host_since + distance_from_center +
                   host_total_listings_count + accommodates + bedrooms + 
                   Air_conditioning + Heating + Kitchen + Elevator +
                   minimum_nights + availability_30 + availability_90 +
                   review_scores_cleanliness + number_of_reviews + reviews_per_month +
                   review_scores_location + review_scores_value + review_scores_rating +
                   instant_bookable + entire_home + shared_room + private_room + 
                   spring + summer + fall + winter, 
                 data=NY_reduced_train, distribution = "gaussian",
                 interaction.depth=6, n.trees=5000, shrinkage=.05, cv.folds = 2)

# Root mean squared error - log price
RMSE3 = tibble("model" = c("lm_null", "lm2", "lm3", "lm_lasso1", "BNB.tree1", 
                           "BNB.forest1", "BNB.boost1"),
               "RMSE" = c(rmse(lm_null, NY_reduced_test), 
                          rmse(lm2, NY_reduced_test), 
                          rmse(lm3, NY_reduced_test), 
                          rmse(lm_lasso1, NY_reduced_test), 
                          rmse(BNB.tree1, NY_reduced_test), 
                          rmse(BNB.forest1, NY_reduced_test), 
                          rmse(BNB.boost1, NY_reduced_test)))
RMSE3.1 = kable(RMSE3, caption = "RMSE of each model (log price)")
RMSE3.1
```

 

Below, we see two variable importance plots; the first represents the increase in node purity from each variable, and the second represents the percent increase in MSE if that variable is omitted. In general, the variables that have the most impact on the model are normalized latitude & longitude and distance_from_center (location), room type, minimum length of stay, number of guests the listing can accommodate, and reviews per month. The least important variables in our model are, in general, the seasonal variables and the amenity variables.

 

```{r 4.1, fig.height=3.5}
# Variable Importance:
##varImpPlot(BNB.forest1)
imp <- importance(BNB.forest1)
imp_df <- data.frame(Var = rownames(imp), Importance = imp[, "IncNodePurity"], stringsAsFactors = FALSE)
long_imp <- reshape2::melt(imp_df, id.vars = "Var")

# Convert the importance data frame to a long format
long_imp <- reshape2::melt(imp_df, id.vars = "Var")

# Create the plot
clean_varimp_plot <- ggplot(long_imp, aes(x = reorder(Var, value), y = value, fill = Var)) +
  geom_bar(stat = "identity") +
  coord_flip() +
  theme_minimal() +
  theme(axis.ticks.y = element_blank(),
        axis.title.y = element_blank(),
        legend.position = "none") +
  xlab("Variable") +
  ylab("Importance (IncNodePurity)")

# Show the plot
print(clean_varimp_plot)
```

 

```{r 4.2, fig.height=3.5}
# Variable Importance:
##varImpPlot(BNB.forest1)
imp_df1 <- data.frame(Var = rownames(imp), Importance = imp[, "%IncMSE"], stringsAsFactors = FALSE)
long_imp1 <- reshape2::melt(imp_df1, id.vars = "Var")

# Create the plot
clean_varimp_plot1 <- ggplot(long_imp1, aes(x = reorder(Var, value), y = value, fill = Var)) +
  geom_bar(stat = "identity") +
  coord_flip() +
  theme_minimal() +
  theme(axis.ticks.y = element_blank(),
        axis.title.y = element_blank(),
        legend.position = "none") +
  xlab("Variable") +
  ylab("Importance (%IncMSE)")

# Show the plot
print(clean_varimp_plot1)
```

 

### Mapping

```{r 6}
# Additional Data Manipulation
# Calculate the mean price per neighborhood
neighborhood_price <- NY_reduced %>%
  group_by(neighbourhood_cleansed) %>%
  summarize(neighborhood_price = mean(price, na.rm = TRUE))

NY_reduced <- merge(NY_reduced, neighborhood_price, by = "neighbourhood_cleansed")

# get predicted values for all listings
forest1 = randomForest(log_price ~ spatial_cluster + latitude_normalized * longitude_normalized + 
                             host_since + neighbourhood_group_cleansed +
                             Air_conditioning + Heating + Kitchen + Elevator +
                             host_total_listings_count + accommodates + bedrooms +
                             minimum_nights + availability_30 + availability_90 +
                             reviews_per_month + review_scores_location +
                             number_of_reviews + review_scores_cleanliness +
                             review_scores_value + review_scores_rating +
                             instant_bookable + entire_home + shared_room + 
                             private_room + spring + summer + fall + winter,
                         data=NY_reduced, importance=TRUE)

#add predictions to data
NY_reduced = NY_reduced %>%
  mutate(price_forest1_pred = predict(forest1))

# group by neighborhood, get mean predicted price, convert back from log
neighborhood_pred_price <- NY_reduced %>%
  group_by(neighbourhood_cleansed) %>%
  summarize(neighborhood_predicted_price = mean(price_forest1_pred)) %>%
  mutate(neighborhood_pred_price_conv = exp(neighborhood_predicted_price))

# Merge the data frames by the common column 'neighbourhood_cleansed'
NY_reduced  <- merge(NY_reduced, neighborhood_pred_price, 
                       by = "neighbourhood_cleansed")

#create error measurements
NY_reduced <- NY_reduced %>%
  mutate("resid1" = abs(price_forest1_pred - log_price)) %>%
  mutate("percentErr1" = resid1/log_price)

# Calculate the mean price error rate per neighborhood
neighborhood_error <- NY_reduced %>%
  group_by(neighbourhood_cleansed) %>%
  summarize(neighborhood_error = mean(percentErr1, na.rm = TRUE))

# Merge the data frames by the common column 'neighbourhood_cleansed'
NY_reduced <- merge(NY_reduced, neighborhood_error, 
                       by = "neighbourhood_cleansed")
```

Here we see the maps of true neighborhood (not borough; recall that, while there are 5 boroughs in NYC, there are over 250 neighborhoods in our dataset) as coded in the dataset, versus spatial cluster as predicted by the DBSCAN algorithm.

The spatial clusters do a reasonably good job of telling the difference between Manhattan, Brooklyn, and everywhere else, but they are not nearly as fine-grained as the true neighborhoods from the dataset. This might explain why they are only a moderately important predictor of our random forest model.

 

```{r 7, fig.height=4}
## Geography of Price
library(plotly)

NY_reduced_sf <- st_as_sf(NY_reduced, coords = c("longitude", "latitude"), 
                             crs = 4326)

geojson_file <- "/Users/jack/Documents/GitHub/Data-Mining-Statistical-Learning/Final Project/Borough_Boundaries.geojson"

# Read the GeoJSON file
nyc_shapefile <- st_read(geojson_file, quiet=TRUE)
nyc_shapefile2 <- nyc_shapefile %>%
  st_transform(crs = st_crs(NY_reduced_sf))

## True Neighborhoods
plot1 <- ggplot() +
  geom_sf(data = nyc_shapefile2, fill = "lightgray", color = "black", size = 0.2) +
  geom_sf(data = NY_reduced_sf, aes(color = neighbourhood_cleansed), size = .2) +
  theme_minimal() +
  labs(title = "True Neighborhoods",
       color = "Neighborhood") +
  theme(legend.position = "none")
plot1
```

 

```{r 7.0.1, fig.height=4}
## Spatial Clusters
# Create the plot
plot2 <- ggplot() +
  geom_sf(data = nyc_shapefile2, fill = "lightgray", color = "black", size = 0.2) +
  geom_sf(data = NY_reduced_sf, aes(color = ifelse(spatial_cluster == 0, "pink",
                                                      spatial_cluster)), size = .2) +
  theme_minimal() +
  labs(title = "Spatial Clusters (DBSCAN)",
       color = "Cluster (if not in cluster, listing is pink)") +
  theme(legend.position = "none")
plot2
```

 

Below, we see first the map of mean predicted price by neighborhood (converted back from log form for interpretability), followed by the map of actual mean price by neighborhood.

 

```{r 7.1, fig.height=4}
## Mapping Price
# Predicted Price by Neighborhood
plot3 <- ggplot() +
  geom_sf(data = nyc_shapefile2, fill = "lightgray", color = "black", size = 0.2) +
  geom_sf(data = NY_reduced_sf, aes(color = neighborhood_pred_price_conv), size = .2) +
  scale_color_gradientn(colours = viridisLite::viridis(10),
                        limits = c(0, 400),
                        name = "Pred. Price") +
  theme_minimal() +
  labs(title = "Predicted Price by Neighborhood",
       color = "Pred. Price")
plot3
```

 

```{r 7.1.1, fig.height=4}
# True Price by Neighborhood
plot4 <- ggplot() +
  geom_sf(data = nyc_shapefile2, fill = "lightgray", color = "black", size = 0.2) +
  geom_sf(data = NY_reduced_sf, aes(color = neighborhood_price), size = .2) +
  scale_color_gradientn(colours = viridisLite::viridis(10),
                        limits = c(0, 400),
                        name = "True Price") +
  theme_minimal() +
  labs(title = "True Price by Neighborhood",
       color = "True Price")
plot4
```

 

And below, we see the mean residual error rate of our model's predicted price in each neighborhood:

 

```{r 7.2, fig.height=4}
# Residual Error of Price
ggplot() +
  geom_sf(data = nyc_shapefile2, fill = "lightgray", color = "black", size = 0.2) +
  geom_sf(data = NY_reduced_sf, aes(color = 100*neighborhood_error), size = .2) +
  scale_color_gradientn(colours = viridisLite::plasma(10),
                        name = "Residual Error Rate") +
  theme_minimal() +
  labs(title = "Residual Error Rate by Neighborhood - Log Price",
       color = "Residual Error Rate")
```

 

## Conclusion:

Of all the models we examined to predict the price of New York City's Airbnbs, the random forest model produced the best results, with an RMSE of about 0.323. There are a few potential reasons random forest worked better than other methods. By using ensemble learning to average the predictions of individual trees, random forest models reduce the risk of overfitting. Also, by bootstrap aggregating multiple decision trees, the random forest method increases the model's diversity and robustness and reduces the variance in the predictions. Finally, by selecting a random subset of features at each split, random forests introduce additional diversity into the model, which helps to improve the generalization of the model to new data.

In spite of these factors, we ended up with a relatively high RMSE: our model's predicted price was, on average, 38% off the true price of the listing. There are several possible reasons for this high RMSE. The first subset of potential issues is with the model itself. While we tried several different combinations of features in our random forest model, there could still be issues in feature selection that increase the model's error. It's also possible that, given the complexity and number of features, our model in fact suffers from overfitting and thus generalizes poorly to the test data.

Another subset of potential issues is with the data itself. As seen above, price is a variable with a lot of upper outliers in our dataset; even after limiting the dataset to listings with price between \$0 and \$1500, 75% of listings fall into the range between \$0 and \$200, with the rest above. This is a significant challenge for any model to accurately predict price. Our model might also not be capturing location as well as necessary. The location of the listing is an extremely important factor in its price, as seen in the maps above. Our model considered neighborhood group, spatial cluster, Haversine distance from Lower Manhattan, and the interaction between normalized latitude and longitude; still, these are relatively crude proxies for location, and a more precise geographic variable would have been desired.

A final hypothesis for the high RMSE for price is that Airbnb pricing in New York City is highly idiosyncratic. Some hosts have other jobs and view hosting as a side gig. As a result, they may lack expertise in the real estate field and struggle with determining precise pricing. In contrast, long-term rentals or hosts with many listings may set prices more competitively and responsively to the market, leading to greater predictability in pricing.

The most important variables in our model, in terms of both node purity and impact on RMSE, included location (normalized latitude & longitude, spatial_cluster, and distance_from_center), entire_home, private_room, bedrooms, minimum_nights, and host-specific features like review_scores_rating and host_since. We posit that there are four categories of features that best predict price:

-   Location: There is a wide spread between the mean price for a neighborhood like Midtown Manhattan and one like, say, Jackson Heights, Queens or West Bronx. Proximity to tourist attractions and conference centers, crime rates, transit access, real estate cost, and other factors make some neighborhoods much more desirable than others; that comes with a price premium.

-   Property type: Hosts charge much more for entire homes than they do for private or shared rooms, likely because travelers see having access to an entire home as an important amenity that they are willing to pay more for. And the number of bedrooms and guests that a listing accommodates are also important; travelers are willing to pay more per night for a listing that hosts more people.

-   Minimum nights: Some hosts seem to aim their listings at tourists, with minimum stay lengths between 1 and 5 nights; others aim their listings at longer-stay travelers or subletters, with minimum stay lengths of 30 nights or longer. The latter listings likely have a lower price per night than the former, since these travellers are "buying in bulk."

-   Host-specific features: Some features, like review scores and how long a host has been on Airbnb, are endogenous to the hosts. Travelers might be willing to pay more for a listing with higher review scores or a listing that has been active for longer. And hosts might "learn by doing," setting prices more savvily as they gain experience and better reviews.

The features that are least important to predicting price in our model, in general, are those relating to season (spring, summer, fall, and winter) and those relating to amenities (heating, air conditioning, kitchen, etc.). For seasonality, this could be related to the shortcoming of our data that we only have the price for one day in each season, rather than price data every day for a year. We could thereby be missing important intra-seasonal shifts in price. However, this concern is mitigated by the fact that most listings for which we have four observations had identical prices at all four times; this suggests that many hosts simply keep the same price throughout much or all of the year. And for amenities, 90% of listings included a kitchen, 78% had heating, and 68% had air conditioning; one potential explanation is that since so many listings include these amenities, on the margin they do not impact price much.

In terms of the relative predictive value of our model in different New York neighborhoods, it performed with broadly stable error rates in most of the city. Average errors by neighborhood were roughly 5-6% in most of Manhattan above Midtown, and in most of Brooklyn outside of Downtown Brooklyn. Our model's neighborhood error rates were more erratic in sparse areas on the outskirts of the city, including the furthest reaches of Staten Island and Queens, and somewhat higher (6-8%) in the most expensive areas of Lower Manhattan and Downtown Brooklyn. We hypothesize that the low density of listings in the outermost areas of the city gave our model a hard time, and that our model was not sufficiently sensitive to spatial location to capture the high prices of the most desirable Airbnb locations in New York.

These findings might prove useful to NYC's Airbnb hosts and travelers alike. Hosts can learn that the location of their property, property type, minimum stay requirements, and their own reputation as a host are crucial factors in determining the price they can set for their listings. To maximize their earnings, hosts should focus on providing a clean, comfortable, and well-maintained property that caters to their target market, whether it be short-term tourists or longer-term renters. They should also strive to maintain high review scores and promptly address any concerns raised by guests. However, we caution against hosts reading too much into our model. It is most relevant for hosts who have had a NYC listing for at least a year, and the relatively high error rate of our model might indicate that there are factors beyond what our model considered that are important in setting price.

Travelers can learn from these findings that location, property type, and host-specific features are significant determinants of the price they can expect to pay for an Airbnb accommodation. When searching for a suitable place to stay, travelers should compare listings with similar attributes, such as the number of bedrooms or guest capacity, to identify potential deals and make more informed decisions about where to stay. Finally, understanding that seasonal factors and certain amenities may not have a substantial impact on price can help travelers find the best value for their money. This is especially true if Airbnb listing prices are less responsive to season than hotels; in this case, Airbnbs might prove to be better deals on the margin than hotels during "high seasons", and worse deals on the margin during "low seasons." Again, travelers should be cautioned about the limited number of seasonal price data points, and the relatively high error rate of our model, and take these findings with a grain of salt.

&nbsp;

## Appendix: Excluded Approaches

As an aside, we'd like to mention a couple of approaches to this question we tried that did not work, or did not prove useful, and are thus not included below. They include:

-   Completing all the same analysis, but for occupancy rate: Our original question was about predicting New York's Airbnb occupancy rate, in addition to price. However, occupancy rate was not a variable we had access to in the dataset, so we sought to construct the occupancy rate for each listing. We realized that the algorithm that others who have studied Airbnb's occupancy rates have used (monthly reviews x expected review rate x average stay length) relied on the faulty assumptions that expected review rate and stay length are constant for all listings in the dataset. Rather than using an algorithm based on such faulty assumptions, we decided to forgo our analysis of occupancy rate and instead limit our analysis to price.

-   Topic Modeling: We tried using the topic modeling technique of Latent Dirichlet Allocation (LDA) to extract key words and topics from the names and descriptions of the listings. Unfortunately, upon performing this analysis, the topics were insufficiently differentiated from each other (e.g., four topics under the heading "apartment" in the top 10), and the coefficient of each topic was so low, that they yielded very little insight into predicted price and we excluded the results from this report. However, in a similar vein, we did pull out six key words from the amenities column and created new dummy variables to use as predictors in our models: pets_allowed, kitchen, heating, air_conditioning, elevator, and long_term_allowed.

-   PCA:

Principal component analysis (PCA) is a technique used to obtain reduced-dimensional representations of high-dimensional data sets. In the case of our model, which has 48 features, we were motivated to explore the effectiveness of PCA in summarizing the data. We experimented with PCA using two different approaches.

In the first approach, we applied PCA to all of the numerical variables, reducing the dimensionality to rank=8. We then used these 8 variables to estimate prices using a random forest model. However, the RMSE of this model tended to be higher than 0.4, which is not acceptable.

In our second approach, we categorized the features into two groups based on their relevance to hosting and the physical place. The first category included host-specific features such as "host_since", "host_total_listings_count", "host_identity_verified", and others. The second category included place-specific features such as "bedrooms", "room_type", "accommodates", and others. We then applied PCA separately to each category, with rank equal to 3 for the host-related features and rank equal to 5 for the place-related features. We used these reduced-dimensional representations in a random forest model to estimate prices. According to our simulations, the RMSE results were between 0.36 to 0.38.

Although the accuracy of neither approach was better than the overall model, the second method, which utilized only 8 variables, yielded a RMSE that was relatively close to the best result. This suggests that reducing the dimensionality of the place-related features using PCA may have some potential in improving the model's performance. (If you'd like to reproduce our analysis, we included our PCA code as comments in the code block below; simply remove the first \# from each line of code.)

```{r 2.4}
##### for PCA
# set.seed(5)
# NY_reduced2 <- NY_reduced %>% select(where(is.integer) | where(is.logical) | where(is.numeric))

# price_columns <- NY_reduced2[, c("price", "log_price")]

# NY_reduced2 <- NY_reduced2 %>% select(-price, -log_price, -id) 

### principal component regression
# PCA1 = prcomp(NY_reduced2, scale=TRUE, rank=8)
# summary(PCA1)
# P1=PCA1$x
# PCA1_data <- data.frame(P1)
# price_data <- data.frame(price_columns)
# PCA1_data <- merge(PCA1_data, price_data, by = 'row.names')
# PCA1_data$Row.names <- NULL

# PCA1_split =  initial_split(PCA1_data, prop=0.8)
# PCA1_train = training(PCA1_split)
# PCA1_test  = testing(PCA1_split)

### random forest
# BNB.forest2 = randomForest(log_price ~ PC1 + PC2 + PC3 + PC4 + PC5 + PC6 + PC7 + PC8, data=PCA1_train, importance=TRUE)
# modelr::rmse(BNB.forest2, PCA1_test)

### Extract the columns that are relevant to host 
# host_relevant_columns <- NY_reduced2[, c("host_since", "host_total_listings_count", "host_identity_verified", "review_scores_accuracy", "review_scores_cleanliness", "review_scores_checkin", "review_scores_communication", "instant_bookable", "number_of_reviews")]

### Extract the columns that are relevant to place 
# place_relevant_columns <- NY_reduced2[, c( "latitude", "longitude", "accommodates", "bedrooms", "beds", "shared_room", "private_room", "entire_home", "hotel_room", "Kitchen", "Elevator", "Air_conditioning", "Heating")]

### Now look at PCA  
# PCA_host = prcomp(host_relevant_columns, scale=TRUE, rank=3)
# summary(PCA_host)

# PCA_place = prcomp(place_relevant_columns, scale=TRUE, rank=5)
# summary(PCA_place)

# P2=PCA_host$x
# P3=PCA_place$x

# PCA_host_d <- data.frame(P2)
# PCA_place_d <- data.frame(P3)

# PCA2_data = merge(PCA_host_d, PCA_place_d, by = 'row.names')

### Add row.names as a separate column in each data frame
# price_data$Row.names <- row.names(price_data)

### Merge data frames by row.names
# PCA2_data <- merge(PCA2_data, price_data, by = 'Row.names')

### Remove the redundant Row.names column
# PCA2_data$Row.names <- NULL
# head(PCA2_data)

# PCA2_split =  initial_split(PCA2_data, prop=0.8)
# PCA2_train = training(PCA2_split)
# PCA2_test  = testing(PCA2_split)

### random forest
# BNB.forest3 = randomForest(log_price ~ PC1.x + PC2.x + PC3.x + PC1.y + PC2.y + PC3.y + PC4 + PC5, data=PCA2_train, importance=TRUE)
# modelr::rmse(BNB.forest3, PCA2_test)

#######
### here we have different correlation plots, but I dont think they are helpful:
# host_correlation_matrix <- cor(host_relevant_columns)
# place_correlation_matrix <- cor(place_relevant_columns)

# ggcorrplot(host_correlation_matrix,
           # hc.order = TRUE, # Reorder variables based on hierarchical clustering
           # type = "full", # Show full correlation coefficients
           # lab = TRUE, # Show correlation coefficient values on the plot
           # lab_size = 4, # Set font size for correlation coefficient values
           # tl.cex = 12, # Set font size for variable names
           # colors = c("#3c7e9e", "white", "#d93a48"), # Set color palette for positive, neutral, and negative correlations
           # title = "Correlation Plot for host_relevant_columns Matrix") 

# ggcorrplot(place_correlation_matrix,
           # hc.order = TRUE, 
           # type = "full",
           # lab = TRUE, 
           # lab_size = 4, 
           # tl.cex = 12, 
           # colors = c("#3c7e9e", "white", "#d93a48"), 
           # title = "Correlation Plot for Relevant Columns") 
```